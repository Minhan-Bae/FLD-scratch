{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Make pseudo 27 point annotated imageset__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import timm\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set data path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/data/komedi/backup/opendataset/helen\"\n",
    "file_list = os.listdir(path)\n",
    "\n",
    "name_list = []\n",
    "for idx in (range(len(file_list))):\n",
    "    name_list.append(os.path.join(path,file_list[idx]))\n",
    "    \n",
    "print(f\"{len(name_list)} of images are detected \\nDone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define model(facial landmark detection & face detection)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facial landmark detection model\n",
    "def timm_Net_54(model_name, pretrained=None, num_classes=54):\n",
    "    model = timm.create_model(\n",
    "        model_name=model_name,\n",
    "        pretrained=False,\n",
    "        num_classes=num_classes\n",
    "        )\n",
    "\n",
    "    if not pretrained==None:\n",
    "        model.eval()\n",
    "        model.load_state_dict(torch.load(pretrained, map_location = 'cpu'), strict=False)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Face detection model\n",
    "def mtcnn(image, margin=200): #PIL\n",
    "    numpy_image =  np.array(image)\n",
    "    mtcnn = MTCNN(\n",
    "    image_size=512, margin=margin, min_face_size=100,\n",
    "    thresholds=[0.1,0.1,0.1], factor=0.5, post_process=True,\n",
    "    device='cpu', select_largest=True\n",
    "    )\n",
    "    \n",
    "    bbox, _ = mtcnn.detect(numpy_image)\n",
    "    crop_area = (bbox[0][0]-margin//2, # get bbox area with margin\n",
    "                 bbox[0][1]-margin//2,\n",
    "                 bbox[0][2]+margin//2,\n",
    "                 bbox[0][3]+margin//2)\n",
    "    pil_image = Image.fromarray(numpy_image)\n",
    "    crop_img = pil_image.crop(crop_area)\n",
    "    \n",
    "    return crop_img, bbox, np.array(crop_img).shape[0], np.array(crop_img).shape[1]\n",
    "\n",
    "print(\"model is defined \\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"swin_base_patch4_window7_224\"\n",
    "pretrained = \"/data/komedi/pretrained_model/2022-07-08/frontal_27pt_pre0707_swin_base_patch4_window7_224_100.pt\"\n",
    "model = timm_Net_54(model_name, pretrained)\n",
    "\n",
    "print(\"\\n Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(i):\n",
    "    image = Image.open(name_list[i])\n",
    "\n",
    "    crop_img, bbox, h, w = mtcnn(image)\n",
    "    resize_img = TF.resize(crop_img, (224,224))\n",
    "    image_tensor = TF.to_tensor(resize_img)\n",
    "    image_tensor = image_tensor.unsqueeze(0)\n",
    "\n",
    "    predict = model(image_tensor)\n",
    "\n",
    "    landmarks = ((predict.view(-1,2)+0.5)).detach().numpy().tolist()\n",
    "    landmarks = np.array([(int(x*w), int(y*h)) for (x, y) in landmarks if 0 <= x and 0 <= y])\n",
    "    return landmarks, bbox, crop_img\n",
    "\n",
    "print(\"\\n Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make pseudo-csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = \"helen\"\n",
    "csv_lists = []\n",
    "for _, i in enumerate(tqdm(range(len(name_list)))):\n",
    "    # control part\n",
    "    # if i > 1:\n",
    "    #     break\n",
    "    \n",
    "    try:\n",
    "        csv_list = []\n",
    "        \n",
    "        if case == \"kface\":\n",
    "            csv_list.append(os.path.splitext(file_list[i])[0])\n",
    "            csv_list.append(file_list[i].split('_')[1])                \n",
    "            csv_list.append(file_list[i].split('_')[2])\n",
    "            csv_list.append(name_list[i])\n",
    "        else:\n",
    "            csv_list.append(os.path.splitext(file_list[i])[0])\n",
    "            csv_list.append(f\"/data/komedi/confirm_result/{case}/images_crop/{file_list[i]}\")                \n",
    "            csv_list.append('_')            \n",
    "            csv_list.append(name_list[i])\n",
    "            \n",
    "        landmarks, bbox, crop_img = run(i)\n",
    "        for bb in bbox[0]:\n",
    "            csv_list.append(int(bb))\n",
    "        for x,y in landmarks:\n",
    "            csv_list.append((x,y))\n",
    "        crop_img.save(f\"/data/komedi/confirm_result/{case}/images_crop/{file_list[i]}\")\n",
    "        \n",
    "        csv_lists.append(csv_list)\n",
    "        df = pd.DataFrame(csv_lists)\n",
    "        df.to_csv(f\"/data/komedi/confirm_result/{case}/{case}_27pt_pseudo.csv\", header=None, index=None)\n",
    "                \n",
    "    except TypeError:\n",
    "        pass\n",
    "\n",
    "print(\"\\n Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make pseudo-jpg file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_csv_path = f\"/data/komedi/confirm_result/{case}/{case}_27pt_pseudo.csv\"\n",
    "pseudo_csv = pd.read_csv(pseudo_csv_path,header=None).values.tolist()\n",
    "\n",
    "for _, pseudo in enumerate(tqdm(pseudo_csv)):\n",
    "    image = cv2.cvtColor(cv2.imread(pseudo[1]),cv2.COLOR_BGR2RGB)\n",
    "    landmarks = pseudo[8:]\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    for landmark in landmarks:\n",
    "        x,y = eval(landmark)\n",
    "        plt.scatter(x,y, s=10)\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"/data/komedi/confirm_result/{case}/images/{pseudo[0]}.jpg\", bbox_inches='tight',pad_inches = 0)\n",
    "\n",
    "print(\"\\n Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('FG-FLD')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d032bec24de8f26ea2ce5b1fbd1f6fe164433d96c079f6cfdc316b720645a670"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
