{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Moudles and Packages\n",
    "import gc\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"axes.grid\"]=False\n",
    "\n",
    "# Import pytorch modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data as D\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from madgrad import MADGRAD\n",
    "\n",
    "import natsort\n",
    "\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from torchsummary import summary\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = 'cuda:3' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(\"__Import modules and packages__\\n\")\n",
    "print(\"| Pytorch version: {}\".format(torch.__version__))\n",
    "print(\"| GPU: {}\".format(torch.cuda.is_available()))\n",
    "print(\"| Device : \",device)\n",
    "print(\"| Device name: \", torch.cuda.get_device_name(0))\n",
    "print(\"| Device count: \", torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import resnet, xception\n",
    "model = xception.XceptionNet(num_classes=40)\n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.dataset.kface_dataset_lateral as K\n",
    "import src.dataset.kface_transform_A as A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.config as C\n",
    "k_dataset_train = K.kfacedataset(\n",
    "    type=\"train\",\n",
    "    transform=A.get_augmentation(data_type=\"train\")\n",
    "    )\n",
    "\n",
    "k_dataset_valid = K.kfacedataset(\n",
    "    type=\"valid\",\n",
    "    transform=A.get_augmentation(data_type=\"valid\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train = int(len(k_dataset_train)*0.8)\n",
    "len_valid = len(k_dataset_train)-len_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, _ = D.random_split(k_dataset_train, [len_train, len_valid])\n",
    "_, valid_dataset = D.random_split(k_dataset_valid, [len_train, len_valid])\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = D.DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "valid_loader = D.DataLoader(\n",
    "    valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f'{len(train_dataset)} images for training')\n",
    "print(f'{len(valid_dataset)} images for validating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.visualize import visualize_image, visualize_batch\n",
    "\n",
    "image1, landmarks1 = train_dataset[0]\n",
    "print(image1.shape)\n",
    "visualize_image(image1, landmarks1)\n",
    "\n",
    "image2, landmarks2 = train_dataset[0]\n",
    "visualize_image(image2, landmarks2)\n",
    "\n",
    "image3, landmarks3 = train_dataset[0]\n",
    "visualize_image(image3, landmarks3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_loader:\n",
    "    break\n",
    "\n",
    "print(x.shape, y.shape, x.max(), x.min(), y.max(), y.min())\n",
    "\n",
    "for x, y in valid_loader:\n",
    "    break\n",
    "\n",
    "print(x.shape, y.shape, x.max(), x.min(), y.max(), y.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_batch(x[:4], y[:4], y[:4], shape = (2, 2), size = 16, title = 'Training Batch Samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**loss and optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "objective = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.00002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**define validation function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "model.eval()\n",
    "@torch.no_grad()\n",
    "def validate(save = None):\n",
    "    cum_loss = 0.0\n",
    "\n",
    "    for features, labels in valid_loader:\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        with autocast(enabled=True):\n",
    "            outputs = model(features)\n",
    "            loss = objective(outputs, labels)\n",
    "            \n",
    "        cum_loss += loss.item()\n",
    "\n",
    "        break\n",
    "        \n",
    "    visualize_batch(features[:4].cpu(), outputs[:4].cpu(), labels[:4].cpu(),\n",
    "                    shape = (2, 2), size = 16, title = 'Validation sample predictions', save = save)\n",
    "\n",
    "    return cum_loss/len(valid_loader)\n",
    "\n",
    "validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = \"0702\"\n",
    "type = \"lateral\"\n",
    "save_fig_path = f\"logs/kface_progresses{day}_{type}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(save_fig_path):\n",
    "    !rm -rf progress\n",
    "os.mkdir(save_fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|██████▎   | 228/359 [02:12<01:15,  1.73it/s]"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "batches = len(train_loader)\n",
    "best_loss = np.inf\n",
    "optimizer.zero_grad()\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    cum_loss = 0.0\n",
    "    scaler = GradScaler() \n",
    "    model.train()\n",
    "    for idx, (features, labels) in enumerate(tqdm(train_loader, desc= 'Training')):\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with autocast(enabled=True):\n",
    "            model = model.to(device)\n",
    "            \n",
    "            outputs = model(features)\n",
    "        \n",
    "            loss = objective(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        cum_loss += loss.item()\n",
    "        \n",
    "    val_loss = validate(os.path.join(f'/home/ubuntu/workspace/FLD-scratch/logs/kface_progress{day}_{type}',\n",
    "                                     f'epoch({str(epoch + 1).zfill(len(str(epochs)))}).jpg'))\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        print('Saving model....................')\n",
    "        save_model = f'/home/ubuntu/workspace/FLD-scratch/src/models/pretrained_model/{day}/xcep_20pt_{type}_{epoch}epoch_drop05.pth'\n",
    "        torch.save(model.state_dict(), save_model)\n",
    "\n",
    "    print(f'Epoch({epoch + 1}/{epochs}) -> Training Loss: {cum_loss/batches:.8f} | Validation Loss: {val_loss:.8f}')\n",
    "\n",
    "print('Training Complete')\n",
    "print(\"Total Elapsed Time : {} s\".format(time.time()-start_time))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('FG-GLD')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9550210be859de316fbaaac654d2fc4c7fb8b5570e54a571b0ab8123deb4b39d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
