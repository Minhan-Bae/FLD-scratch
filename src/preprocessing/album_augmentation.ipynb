{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import albumentations as A\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = \"train\"\n",
    "\n",
    "data_list = pd.read_csv(f'/data/komedi/dataset/versioning/22-07-19-1200-{cases}-aflw-pose.csv',header=None).values.tolist()\n",
    "print(len(data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_list = pd.read_csv('/data/komedi/dataset/versioning/22-07-15-1600-valid-no300w.csv',header=None).values.tolist()\n",
    "# print(len(data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cases == \"train\":\n",
    "    aug_list = {\n",
    "                # \"rotate15\":A.Rotate((15,15),always_apply=True),\n",
    "                # \"rotate30\":A.Rotate((30,30),always_apply=True),\n",
    "                # \"rotate45\":A.Rotate((45,45),always_apply=True),\n",
    "                # \"rotate60\":A.Rotate((60,60),always_apply=True),\n",
    "                # \"rotate75\":A.Rotate((75,75),always_apply=True),\n",
    "                # \"rotate90\":A.Rotate((90,90),always_apply=True),\n",
    "                # \"rotate_15\":A.Rotate((-15,-15),always_apply=True),\n",
    "                \"rotate_30\":A.Rotate((-30,-30),always_apply=True),\n",
    "                # \"rotate_45\":A.Rotate((-45,-45),always_apply=True),\n",
    "                # \"rotate_60\":A.Rotate((-60,-60),always_apply=True),\n",
    "                # \"rotate_75\":A.Rotate((-75,-75),always_apply=True),\n",
    "                # \"rotate_90\":A.Rotate((-90,-90),always_apply=True),  \n",
    "                              \n",
    "                # \"horizontal\":A.HorizontalFlip(always_apply=True),\n",
    "                # \"resizecrop\":A.RandomResizedCrop(112,112,scale=(0.3,1.0),always_apply=True),\n",
    "                # \"affine1\": A.Affine(scale=(0.5,1),shear=(-45),always_apply=True),\n",
    "                # \"affine2\": A.Affine(scale=(0.5,1),shear=(-15,15),always_apply=True),\n",
    "                # \"affine3\": A.Affine(scale=(0.5,1),shear=(15,45),always_apply=True),\n",
    "                # \"affine4\": A.Affine(scale=(1,1.5),shear=(-45,-15),always_apply=True),\n",
    "                # \"affine5\": A.Affine(scale=(1,1.5),shear=(-15,15),always_apply=True),\n",
    "                # \"affine6\": A.Affine(scale=(1,1.5),shear=(15,45),always_apply=True),                \n",
    "                # \"rotate\":A.Rotate(always_apply=True),\n",
    "                # \"affine7\": A.Affine(scale=(1.5,2.0),shear=(-45,-15),always_apply=True),\n",
    "                # \"affine8\": A.Affine(scale=(1.5,2.0),shear=(-15,15),always_apply=True),\n",
    "                # \"affine9\": A.Affine(scale=(1.5,2.0),shear=(15,45),always_apply=True),\n",
    "                # \"shiftscalerotate\":A.ShiftScaleRotate(border_mode=1, always_apply=True),\n",
    "                # \"normal\":None,\n",
    "                # \"huesaturate\":A.HueSaturationValue(always_apply=True),\n",
    "                # \"gausianblur\":A.GaussianBlur(p=0.5),\n",
    "                # \"gaussnoise\":A.GaussNoise(always_apply=True),\n",
    "                # \"clahe\":A.CLAHE(always_apply=True),\n",
    "                # \"imagecomp\":A.ImageCompression(always_apply=True),\n",
    "                # \"randomgamma\":A.RandomGamma(always_apply=True),\n",
    "                # \"posterize\":A.Posterize(always_apply=True),\n",
    "                # \"blur\":A.Blur(always_apply=True),\n",
    "                # \"colorjitter\":A.ColorJitter (brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, always_apply=False, p=0.5),\n",
    "                # \"bright\":A.RandomBrightnessContrast(contrast_limit=0.5,brightness_limit=0.5,p=0.2)\n",
    "                }\n",
    "    print(len(aug_list.keys()))\n",
    "else:\n",
    "    aug_list = {\"normal\":None}\n",
    "\n",
    "for dir in aug_list.keys():\n",
    "    os.makedirs(f\"/data/komedi/dataset/{cases}/{dir}\",exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "csv_lists = []\n",
    "for idx, data in enumerate(tqdm(data_list)):\n",
    "    # if idx>=10:\n",
    "    #     break\n",
    "    image_name = data[0]\n",
    "\n",
    "    margin = 200\n",
    "    crop_area = (data[3]-margin//2,\n",
    "                    data[4]-margin//2,\n",
    "                    data[5]+margin//2,\n",
    "                    data[6]+margin//2)\n",
    "    \n",
    "    pil_image = Image.open(data[2])\n",
    "    crp_image = pil_image.crop(crop_area)\n",
    "\n",
    "    npy_image = np.array(crp_image)\n",
    "\n",
    "    label = []\n",
    "    for landmark in data[10:]:\n",
    "        x,y = eval(landmark[1:-1])\n",
    "        label.append([x,y])\n",
    "    lst_label = np.array(label)\n",
    "\n",
    "    for types in aug_list.keys():\n",
    "        csv_list = []\n",
    "        if not aug_list[types]:\n",
    "        #     transform = A.Compose([\n",
    "        #         A.Resize(112,112)],\n",
    "        #         keypoint_params = A.KeypointParams(format=\"xy\",remove_invisible = False))\n",
    "            \n",
    "        #     transformed = transform(image=npy_image, keypoints=lst_label)\n",
    "        #     aug_image = transformed['image']\n",
    "        #     aug_label = transformed['keypoints']\n",
    "                    \n",
    "            out_image = npy_image\n",
    "            out_label = lst_label    \n",
    "        else:\n",
    "            transform = A.Compose([\n",
    "                aug_list[types]],\n",
    "                keypoint_params = A.KeypointParams(format=\"xy\",remove_invisible = False))\n",
    "\n",
    "            transformed = transform(image=npy_image, keypoints=lst_label)\n",
    "            aug_image = transformed['image']\n",
    "            aug_label = transformed['keypoints']\n",
    "\n",
    "            out_image = aug_image\n",
    "            out_label = aug_label\n",
    "            \n",
    "        image = Image.fromarray(out_image)\n",
    "        image.save(f\"/data/komedi/dataset/{cases}/{types}/{image_name}\")\n",
    "\n",
    "        csv_list.append(image_name) # 0\n",
    "        csv_list.append(data[1]) # type(aflw)\n",
    "        csv_list.append(f\"/data/komedi/dataset/{cases}/{types}/{image_name}\") # 2\n",
    "        for i in (3,4,5,6):\n",
    "            csv_list.append(data[i])\n",
    "        csv_list.append(-30+data[7]) #pitch\n",
    "        csv_list.append(data[8]) #yaw\n",
    "        csv_list.append(data[9]) #roll\n",
    "        for label in out_label:\n",
    "            x,y = label\n",
    "            csv_list.append((int(x),int(y)))\n",
    "        csv_lists.append(csv_list)\n",
    "        \n",
    "    # random.shuffle(csv_lists)\n",
    "    df = pd.DataFrame(csv_lists)\n",
    "    df.to_csv(f\"/data/komedi/dataset/versioning/22-07-20-1200-rotate_30-{cases}.csv\",header=None, index=None)\n",
    "print(len(csv_lists))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.shuffle(data_list)\n",
    "\"\"\"\n",
    "0: name\n",
    "1 : type(kface, ibug, aflw2000)\n",
    "2: image path\n",
    "3 ~ 6: bbox value(lx, ly, rx, ry)\n",
    "10 ~ 37: facial landmark \n",
    "\"\"\"\n",
    "\n",
    "idx = 16\n",
    "data = data_list[idx]\n",
    "image = Image.open(data[2]).crop((data[3]-100,data[4]-100,data[5]+100,data[6]+100))\n",
    "image = np.array(image)\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)\n",
    "label = []\n",
    "for idx, landmark in enumerate(data[10:]):\n",
    "    x,y = eval(landmark[1:-1])\n",
    "    plt.scatter(x,y,s=5,c='r')\n",
    "    plt.annotate(idx, (x,y))\n",
    "    label.append([x,y])\n",
    "label = np.array(label)\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_list = []\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(always_apply=True)\n",
    "],keypoint_params = A.KeypointParams(format=\"xy\",remove_invisible = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = transform(image=image, keypoints=label)\n",
    "aug_image = transformed['image']\n",
    "aug_label = transformed['keypoints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_image = Image.fromarray(aug_image)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(pil_image)\n",
    "for landmark in aug_label:\n",
    "    x,y = landmark\n",
    "    plt.scatter(x,y,s=5,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('FG-FLD')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d032bec24de8f26ea2ce5b1fbd1f6fe164433d96c079f6cfdc316b720645a670"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
