{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Pytorch version: 1.10.0+cu102\n",
      "| GPU: True\n",
      "| Device :  cuda:1\n",
      "| Device name:  Tesla T4\n",
      "| Device count:  4\n"
     ]
    }
   ],
   "source": [
    "# Import Moudles and Packages\n",
    "import gc\n",
    "import os\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\"\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='3'\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"axes.grid\"]=False\n",
    "\n",
    "# Import pytorch modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data as D\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from madgrad import MADGRAD\n",
    "\n",
    "device = 'cuda:2' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(\"| Pytorch version: {}\".format(torch.__version__))\n",
    "print(\"| GPU: {}\".format(torch.cuda.is_available()))\n",
    "print(\"| Device : \",device)\n",
    "print(\"| Device name: \", torch.cuda.get_device_name(0))\n",
    "print(\"| Device count: \", torch.cuda.device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import local modules\n",
    "from src import config as C\n",
    "from src.models import resnet50d\n",
    "from src.utils.collate_fn import *\n",
    "from src.utils.print_overwrite import *\n",
    "from src.utils.seed import *\n",
    "from src.dataset import w300_dataset as W\n",
    "\n",
    "seed_everything(C.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Size of image in train_loader : torch.Size([16, 1, 512, 512])\n",
      "| Size of label in train_loader : torch.Size([16, 27, 2])\n",
      "| Size of image in train_loader : torch.Size([2, 1, 512, 512])\n",
      "| Size of label in train_loader : torch.Size([2, 27, 2])\n"
     ]
    }
   ],
   "source": [
    "w_dataset = W.FaceLandmarksDataset(transform=W.Transforms(), type=\"valid\")\n",
    "\n",
    "len_valid_set = int(0.2*len(w_dataset))\n",
    "len_train_set = len(w_dataset) - len_valid_set\n",
    "\n",
    "train_dataset , valid_dataset,  = torch.utils.data.random_split(w_dataset , [len_train_set, len_valid_set])\n",
    "\n",
    "# shuffle and batch the datasets\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=2, shuffle=False, num_workers=4)\n",
    "\n",
    "train_images, train_landmarks = next(iter(train_loader))\n",
    "valid_images, valid_landmarks = next(iter(valid_loader))\n",
    "\n",
    "print(f\"| Size of image in train_loader : {train_images.shape}\")\n",
    "print(f\"| Size of label in train_loader : {train_landmarks.shape}\")\n",
    "print(f\"| Size of image in train_loader : {valid_images.shape}\")\n",
    "print(f\"| Size of label in train_loader : {valid_landmarks.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resnet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/workspace/FLD-scratch/home_run_w300.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B133.186.250.203/home/ubuntu/workspace/FLD-scratch/home_run_w300.ipynb#ch0000012vscode-remote?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m resnet\u001b[39m.\u001b[39mresnet18()\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B133.186.250.203/home/ubuntu/workspace/FLD-scratch/home_run_w300.ipynb#ch0000012vscode-remote?line=1'>2</a>\u001b[0m state_dict \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39m/home/ubuntu/workspace/FLD-scratch/result/face_landmarks.pth\u001b[39m\u001b[39m'\u001b[39m,map_location\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B133.186.250.203/home/ubuntu/workspace/FLD-scratch/home_run_w300.ipynb#ch0000012vscode-remote?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(state_dict)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'resnet' is not defined"
     ]
    }
   ],
   "source": [
    "model = resnet.resnet18().cpu()\n",
    "state_dict = torch.load('/home/ubuntu/workspace/FLD-scratch/result/face_landmarks.pth',map_location='cpu')\n",
    "model.load_state_dict(state_dict)\n",
    "model = model.to(device)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    images, landmarks = next(iter(valid_loader))\n",
    "    \n",
    "    images = images.to(device)\n",
    "    landmarks = (landmarks) * 512 #* torch.tensor((512,512))    \n",
    "\n",
    "    predictions = model(images).cpu()\n",
    "    predictions = (predictions) * 512 # torch.tensor((512,512))  \n",
    "    predictions = predictions.view([-1,27,2])\n",
    "    \n",
    "    plt.figure(figsize=(10,20))\n",
    "    \n",
    "    for img_num in range(2):\n",
    "        print(images[img_num].shape)\n",
    "        plt.subplot(2,1,img_num+1)\n",
    "        plt.imshow(images[img_num].cpu().permute(1,2,0).squeeze(), cmap='gray')\n",
    "        plt.scatter(predictions[img_num].T[0], predictions[img_num].T[1], c = 'r', s = 5)\n",
    "        plt.scatter(landmarks[img_num].T[0], landmarks[img_num].T[1], c = 'g', s = 5)\n",
    "\n",
    "print('Total number of test images: {}'.format(len(valid_dataset)))\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Elapsed Time : {}\".format(end_time - start_time)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timm\n",
    "# def FaceSynthetics():\n",
    "#     backbone = timm.create_model(\"resnet50d\",  num_classes=27*2)\n",
    "#     return backbone\n",
    "\n",
    "# x = torch.randn([1, 3, 512, 512]).to(device)\n",
    "# model = FaceSynthetics().to(device)\n",
    "# out = model(x).to(device)\n",
    "# print(f\"input : {x.shape} | output : {out.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = random.randint(0,len(w_dataset))\n",
    "# image, landmarks = w_dataset[idx]\n",
    "# landmarks = (landmarks) * 512\n",
    "# plt.figure(figsize=(5, 5))\n",
    "# plt.imshow(image.numpy().squeeze(), cmap='gray');\n",
    "# plt.scatter(landmarks[:,0], landmarks[:,1], s=8);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('FG-GLD')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9550210be859de316fbaaac654d2fc4c7fb8b5570e54a571b0ab8123deb4b39d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
